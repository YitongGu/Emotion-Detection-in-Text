{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56cccab6",
   "metadata": {},
   "source": [
    "# Emotions Detection in Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0814628-3d83-4fd6-a511-2eccf79f9f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load Data Viz Pkgs\n",
    "import seaborn as sns\n",
    "\n",
    "# Load Text Cleaning Pkgs\n",
    "import neattext.functions as nfx\n",
    "\n",
    "# Load ML Pkgs\n",
    "# Estimators\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Transformers\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b209e004-ab77-4407-8689-b4318944d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv(\"../data/emotion_dataset_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea2d4c0-3bdd-405e-ab69-507ceaac36cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Why ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joy</td>\n",
       "      <td>Sage Act upgrade on my to do list for tommorow.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>joy</td>\n",
       "      <td>Such an eye ! The true hazel eye-and so brill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>joy</td>\n",
       "      <td>@Iluvmiasantos ugh babe.. hugggzzz for u .!  b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                               Text\n",
       "0  neutral                                             Why ? \n",
       "1      joy    Sage Act upgrade on my to do list for tommorow.\n",
       "2  sadness  ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...\n",
       "3      joy   Such an eye ! The true hazel eye-and so brill...\n",
       "4      joy  @Iluvmiasantos ugh babe.. hugggzzz for u .!  b..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "430565a3-cf3b-4c6f-afa5-bafd084f5676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Emotion\n",
       "joy         11045\n",
       "sadness      6722\n",
       "fear         5410\n",
       "anger        4297\n",
       "surprise     4062\n",
       "neutral      2254\n",
       "disgust       856\n",
       "shame         146\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value Counts\n",
    "df['Emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "185e0c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34792"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "531d3449-a959-4a19-bff0-3ffed551e619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Emotion', ylabel='count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "sns.countplot(x='Emotion',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40f991d0-952f-40c1-bf00-f3476ce0436d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BTC_ADDRESS_REGEX',\n",
       " 'CURRENCY_REGEX',\n",
       " 'CURRENCY_SYMB_REGEX',\n",
       " 'Counter',\n",
       " 'DATE_REGEX',\n",
       " 'EMAIL_REGEX',\n",
       " 'EMOJI_REGEX',\n",
       " 'HASTAG_REGEX',\n",
       " 'MASTERCard_REGEX',\n",
       " 'MD5_SHA_REGEX',\n",
       " 'MOST_COMMON_PUNCT_REGEX',\n",
       " 'NUMBERS_REGEX',\n",
       " 'PHONE_REGEX',\n",
       " 'PoBOX_REGEX',\n",
       " 'SPECIAL_CHARACTERS_REGEX',\n",
       " 'STOPWORDS',\n",
       " 'STOPWORDS_de',\n",
       " 'STOPWORDS_en',\n",
       " 'STOPWORDS_es',\n",
       " 'STOPWORDS_fr',\n",
       " 'STOPWORDS_ru',\n",
       " 'STOPWORDS_yo',\n",
       " 'STREET_ADDRESS_REGEX',\n",
       " 'TextFrame',\n",
       " 'URL_PATTERN',\n",
       " 'USER_HANDLES_REGEX',\n",
       " 'VISACard_REGEX',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__generate_text',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__numbers_dict',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_lex_richness_herdan',\n",
       " '_lex_richness_maas_ttr',\n",
       " 'clean_text',\n",
       " 'defaultdict',\n",
       " 'digit2words',\n",
       " 'extract_btc_address',\n",
       " 'extract_currencies',\n",
       " 'extract_currency_symbols',\n",
       " 'extract_dates',\n",
       " 'extract_emails',\n",
       " 'extract_emojis',\n",
       " 'extract_hashtags',\n",
       " 'extract_html_tags',\n",
       " 'extract_mastercard_addr',\n",
       " 'extract_md5sha',\n",
       " 'extract_numbers',\n",
       " 'extract_pattern',\n",
       " 'extract_phone_numbers',\n",
       " 'extract_postoffice_box',\n",
       " 'extract_shortwords',\n",
       " 'extract_special_characters',\n",
       " 'extract_stopwords',\n",
       " 'extract_street_address',\n",
       " 'extract_terms_in_bracket',\n",
       " 'extract_urls',\n",
       " 'extract_userhandles',\n",
       " 'extract_visacard_addr',\n",
       " 'fix_contractions',\n",
       " 'generate_sentence',\n",
       " 'hamming_distance',\n",
       " 'inverse_df',\n",
       " 'lexical_richness',\n",
       " 'markov_chain',\n",
       " 'math',\n",
       " 'nlargest',\n",
       " 'normalize',\n",
       " 'num2words',\n",
       " 'random',\n",
       " 're',\n",
       " 'read_txt',\n",
       " 'remove_accents',\n",
       " 'remove_bad_quotes',\n",
       " 'remove_btc_address',\n",
       " 'remove_currencies',\n",
       " 'remove_currency_symbols',\n",
       " 'remove_custom_pattern',\n",
       " 'remove_custom_words',\n",
       " 'remove_dates',\n",
       " 'remove_emails',\n",
       " 'remove_emojis',\n",
       " 'remove_hashtags',\n",
       " 'remove_html_tags',\n",
       " 'remove_mastercard_addr',\n",
       " 'remove_md5sha',\n",
       " 'remove_multiple_spaces',\n",
       " 'remove_non_ascii',\n",
       " 'remove_numbers',\n",
       " 'remove_phone_numbers',\n",
       " 'remove_postoffice_box',\n",
       " 'remove_puncts',\n",
       " 'remove_punctuations',\n",
       " 'remove_shortwords',\n",
       " 'remove_special_characters',\n",
       " 'remove_stopwords',\n",
       " 'remove_street_address',\n",
       " 'remove_terms_in_bracket',\n",
       " 'remove_urls',\n",
       " 'remove_userhandles',\n",
       " 'remove_visacard_addr',\n",
       " 'replace_bad_quotes',\n",
       " 'replace_currencies',\n",
       " 'replace_currency_symbols',\n",
       " 'replace_dates',\n",
       " 'replace_emails',\n",
       " 'replace_emojis',\n",
       " 'replace_numbers',\n",
       " 'replace_phone_numbers',\n",
       " 'replace_special_characters',\n",
       " 'replace_term',\n",
       " 'replace_urls',\n",
       " 'string',\n",
       " 'term_freq',\n",
       " 'to_txt',\n",
       " 'unicodedata',\n",
       " 'word_freq',\n",
       " 'word_length_freq']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Cleaning\n",
    "dir(nfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1f87847-a91c-4bd6-a307-d746eb5aa9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User handles\n",
    "df['Clean_Text'] = df['Text'].apply(nfx.remove_userhandles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03886bc3-1ac4-4f1b-842b-e5d2d770ff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords\n",
    "df['Clean_Text'] = df['Clean_Text'].apply(nfx.remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffcf4c7",
   "metadata": {},
   "source": [
    "## We are not removing Special Characters as some of the rows have just Special Characters and it'll result into empty row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a0fcc0c-4adf-4f0b-b226-164659ad70ba",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "      <th>Clean_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Why ?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joy</td>\n",
       "      <td>Sage Act upgrade on my to do list for tommorow.</td>\n",
       "      <td>Sage Act upgrade list tommorow.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...</td>\n",
       "      <td>WAY HOMEGIRL BABY FUNERAL!!! MAN HATE FUNERALS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>joy</td>\n",
       "      <td>Such an eye ! The true hazel eye-and so brill...</td>\n",
       "      <td>eye ! true hazel eye-and brilliant ! Regular f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>joy</td>\n",
       "      <td>@Iluvmiasantos ugh babe.. hugggzzz for u .!  b...</td>\n",
       "      <td>ugh babe.. hugggzzz u .! babe naamazed nga ako...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34787</th>\n",
       "      <td>surprise</td>\n",
       "      <td>@MichelGW have you gift! Hope you like it! It'...</td>\n",
       "      <td>gift! Hope like it! hand wear ! It'll warm! Lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34788</th>\n",
       "      <td>joy</td>\n",
       "      <td>The world didnt give it to me..so the world MO...</td>\n",
       "      <td>world didnt me..so world DEFINITELY cnt away!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34789</th>\n",
       "      <td>anger</td>\n",
       "      <td>A man robbed me today .</td>\n",
       "      <td>man robbed today .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34790</th>\n",
       "      <td>fear</td>\n",
       "      <td>Youu call it JEALOUSY, I call it of #Losing YO...</td>\n",
       "      <td>Youu JEALOUSY, #Losing YOU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34791</th>\n",
       "      <td>sadness</td>\n",
       "      <td>I think about you baby, and I dream about you ...</td>\n",
       "      <td>think baby, dream time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34792 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Emotion                                               Text  \\\n",
       "0       neutral                                             Why ?    \n",
       "1           joy    Sage Act upgrade on my to do list for tommorow.   \n",
       "2       sadness  ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...   \n",
       "3           joy   Such an eye ! The true hazel eye-and so brill...   \n",
       "4           joy  @Iluvmiasantos ugh babe.. hugggzzz for u .!  b...   \n",
       "...         ...                                                ...   \n",
       "34787  surprise  @MichelGW have you gift! Hope you like it! It'...   \n",
       "34788       joy  The world didnt give it to me..so the world MO...   \n",
       "34789     anger                           A man robbed me today .    \n",
       "34790      fear  Youu call it JEALOUSY, I call it of #Losing YO...   \n",
       "34791   sadness  I think about you baby, and I dream about you ...   \n",
       "\n",
       "                                              Clean_Text  \n",
       "0                                                      ?  \n",
       "1                        Sage Act upgrade list tommorow.  \n",
       "2      WAY HOMEGIRL BABY FUNERAL!!! MAN HATE FUNERALS...  \n",
       "3      eye ! true hazel eye-and brilliant ! Regular f...  \n",
       "4      ugh babe.. hugggzzz u .! babe naamazed nga ako...  \n",
       "...                                                  ...  \n",
       "34787    gift! Hope like it! hand wear ! It'll warm! Lol  \n",
       "34788    world didnt me..so world DEFINITELY cnt away!!!  \n",
       "34789                                 man robbed today .  \n",
       "34790                      Youu JEALOUSY, #Losing YOU...  \n",
       "34791                             think baby, dream time  \n",
       "\n",
       "[34792 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "450c39c0-79dd-4eaf-85fe-57e344eb81bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features & Labels\n",
    "Xfeatures = df['Text']\n",
    "ylabels = df['Emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99ffab89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in /Users/yitonggu/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages (0.4.9)\n",
      "Requirement already satisfied: httpx>=0.27 in /Users/yitonggu/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in /Users/yitonggu/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages (from ollama) (2.11.5)\n",
      "Requirement already satisfied: anyio in /Users/yitonggu/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages (from httpx>=0.27->ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/yitonggu/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages (from httpx>=0.27->ollama) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/yitonggu/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/yitonggu/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages (from httpx>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/yitonggu/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/yitonggu/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/yitonggu/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages (from pydantic>=2.9->ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/yitonggu/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages (from pydantic>=2.9->ollama) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/yitonggu/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages (from pydantic>=2.9->ollama) (0.4.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/yitonggu/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages (from anyio->httpx>=0.27->ollama) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/yitonggu/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "377c4e98-67f0-45e5-8dd5-0417585754f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ollama\n",
    "# import pandas as pd\n",
    "\n",
    "# # Load the same dataset used for training/testing\n",
    "# df = pd.read_csv(\"../data/emotion_dataset_raw.csv\")  # adjust the path if needed\n",
    "# emotion_labels = ['neutral', 'joy', 'sadness', 'fear', 'surprise', 'anger', 'shame','disgust']\n",
    "\n",
    "\n",
    "# # Define your LLM prompt function\n",
    "# def classify_emotion_llm(text):\n",
    "#     prompt = f\"Classify the emotion in the following sentence: '{text}'. Choose from: ['neutral', 'joy', 'sadness', 'fear', 'surprise', 'anger', 'shame', 'disgust']. Answer in one word.\"\n",
    "#     # ret = \"Unknown\"\n",
    "#     while True:\n",
    "#         response = ollama.chat(\n",
    "#             model='mistral',  # You can switch to 'tinyllama', 'llama2', etc.\n",
    "#             messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "#         )\n",
    "#         raw = response['message']['content'].strip()\n",
    "#         for label in emotion_labels:\n",
    "#             if label.lower() in raw.lower():\n",
    "#                 return label\n",
    "#     # return \"Unknown\"\n",
    "\n",
    "# # Apply to a sample of the dataset for speed (e.g., first 100 rows)\n",
    "# df_sample = df[['Text']].dropna().head(100).copy()\n",
    "# df_sample['LLM_Prediction'] = df_sample['Text'].apply(classify_emotion_llm)\n",
    "\n",
    "# # Show results\n",
    "# print(df_sample[['Text', 'LLM_Prediction']].head())\n",
    "\n",
    "# # Save output\n",
    "# df_sample.to_csv(\"llm_predictions_sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1ababb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Load ground truth labels\n",
    "# df_truth = pd.read_csv(\"../data/emotion_dataset_raw.csv\")\n",
    "# df_truth = df_truth[['Text', 'Emotion']].dropna().head(100).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# # Load LLM predictions\n",
    "# df_pred = pd.read_csv(\"llm_predictions_sample.csv\")\n",
    "# df_pred = df_pred[['Text', 'LLM_Prediction']].dropna().reset_index(drop=True)\n",
    "\n",
    "# # Merge and normalize\n",
    "# df_compare = df_truth.copy()\n",
    "# df_compare['LLM_Prediction'] = df_pred['LLM_Prediction'].str.strip().str.lower()\n",
    "# df_compare['Emotion'] = df_compare['Emotion'].str.strip().str.lower()\n",
    "\n",
    "# # Overall accuracy\n",
    "# overall_accuracy = accuracy_score(df_compare['Emotion'], df_compare['LLM_Prediction'])\n",
    "# print(f\"Overall Accuracy: {overall_accuracy:.2f}\")\n",
    "\n",
    "# # Accuracy per emotion\n",
    "# print(\"\\nAccuracy per Emotion:\")\n",
    "# for emotion in df_compare['Emotion'].unique():\n",
    "#     subset = df_compare[df_compare['Emotion'] == emotion]\n",
    "#     correct = (subset['Emotion'] == subset['LLM_Prediction']).sum()\n",
    "#     total = len(subset)\n",
    "#     print(f\"{emotion.title()}: {correct}/{total} = {correct/total:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58531482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_compare['Emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61d19a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def llm_flow(model_name):\n",
    "    def classify_emotion_llm(text):\n",
    "        prompt = f\"Classify the emotion in the following sentence: '{text}'. Choose from: ['neutral', 'joy', 'sadness', 'fear', 'surprise', 'anger', 'shame', 'disgust']. Answer in one word.\"\n",
    "        while True:\n",
    "            response = ollama.chat(\n",
    "                model=model_name, \n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            raw = response['message']['content'].strip()\n",
    "            for label in emotion_labels:\n",
    "                if label.lower() in raw.lower():\n",
    "                    return label\n",
    "\n",
    "    # Apply to a sample of the dataset for speed (e.g., first 100 rows)\n",
    "    df_sample = df[['Text']].dropna().copy()\n",
    "    df_sample['LLM_Prediction'] = df_sample['Text'].apply(classify_emotion_llm)\n",
    "\n",
    "    # Show results\n",
    "    print(df_sample[['Text', 'LLM_Prediction']].head())\n",
    "\n",
    "    # Save output\n",
    "    df_sample.to_csv(model_name + \"_predictions_sample.csv\", index=False)\n",
    "    \n",
    "    df_truth = pd.read_csv(\"../data/emotion_dataset_raw.csv\")\n",
    "    df_truth = df_truth[['Text', 'Emotion']].dropna().reset_index(drop=True)\n",
    "\n",
    "    # Load LLM predictions\n",
    "    df_pred = pd.read_csv(model_name+\"_predictions_sample.csv\")\n",
    "    df_pred = df_pred[['Text', 'LLM_Prediction']].dropna().reset_index(drop=True)\n",
    "\n",
    "    # Merge and normalize\n",
    "    df_compare = df_truth.copy()\n",
    "    df_compare['LLM_Prediction'] = df_pred['LLM_Prediction'].str.strip().str.lower()\n",
    "    df_compare['Emotion'] = df_compare['Emotion'].str.strip().str.lower()\n",
    "\n",
    "    # Overall accuracy\n",
    "    overall_accuracy = accuracy_score(df_compare['Emotion'], df_compare['LLM_Prediction'])\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.2f}\")\n",
    "\n",
    "    # Accuracy per emotion\n",
    "    print(\"\\nAccuracy per Emotion:\")\n",
    "    for emotion in df_compare['Emotion'].unique():\n",
    "        subset = df_compare[df_compare['Emotion'] == emotion]\n",
    "        correct = (subset['Emotion'] == subset['LLM_Prediction']).sum()\n",
    "        total = len(subset)\n",
    "        print(f\"{emotion.title()}: {correct}/{total} = {correct/total:.2f}\")\n",
    "    print(model_name, \"finish\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35874b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_models = [\n",
    "    \"mistral\",\n",
    "    \"llama2\",\n",
    "    \"tinyllama\",\n",
    "    # \"phi\",\n",
    "    # \"gemma\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12871f76",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mllm_flow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mollama_models\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[36], line 20\u001b[0m, in \u001b[0;36mllm_flow\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Apply to a sample of the dataset for speed (e.g., first 100 rows)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m df_sample \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 20\u001b[0m df_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLLM_Prediction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_sample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mText\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassify_emotion_llm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Show results\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_sample[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLLM_Prediction\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[36], line 9\u001b[0m, in \u001b[0;36mllm_flow.<locals>.classify_emotion_llm\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      7\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassify the emotion in the following sentence: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Choose from: [\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjoy\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msadness\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfear\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurprise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manger\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshame\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisgust\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]. Answer in one word.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 9\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mollama\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     raw \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m emotion_labels:\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/ollama/_client.py:335\u001b[0m, in \u001b[0;36mClient.chat\u001b[0;34m(self, model, messages, tools, stream, format, options, keep_alive)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mchat\u001b[39m(\n\u001b[1;32m    292\u001b[0m   \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    293\u001b[0m   model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    300\u001b[0m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    301\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ChatResponse, Iterator[ChatResponse]]:\n\u001b[1;32m    302\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;124;03m  Create a chat response using the requested model.\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 335\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mChatResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/chat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/ollama/_client.py:180\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, cls, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpart)\n\u001b[1;32m    178\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/ollama/_client.py:120\u001b[0m, in \u001b[0;36mClient._request_raw\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_request_raw\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    119\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     r\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/httpx/_client.py:825\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    810\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    812\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m    813\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    814\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    823\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m    824\u001b[0m )\n\u001b[0;32m--> 825\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/httpcore/_sync/http11.py:214\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions({h11\u001b[38;5;241m.\u001b[39mRemoteProtocolError: RemoteProtocolError}):\n\u001b[0;32m--> 214\u001b[0m         event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_h11_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m    217\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[1;32m    218\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    219\u001b[0m         )\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/h11/_connection.py:481\u001b[0m, in \u001b[0;36mConnection.next_event\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt receive data when peer state is ERROR\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 481\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_next_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [NEED_DATA, PAUSED]:\n\u001b[1;32m    483\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_event(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtheir_role, cast(Event, event))\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/h11/_connection.py:423\u001b[0m, in \u001b[0;36mConnection._extract_next_receive_event\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PAUSED\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 423\u001b[0m event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_buffer \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_buffer_closed:\n\u001b[1;32m    426\u001b[0m         \u001b[38;5;66;03m# In some unusual cases (basically just HTTP/1.0 bodies), EOF\u001b[39;00m\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;66;03m# triggers an actual protocol event; in that case, we want to\u001b[39;00m\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;66;03m# return that event, and then the state will change and we'll\u001b[39;00m\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;66;03m# get called again to generate the actual ConnectionClosed().\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/h11/_readers.py:113\u001b[0m, in \u001b[0;36mmaybe_read_from_SEND_RESPONSE_server\u001b[0;34m(buf)\u001b[0m\n\u001b[1;32m    109\u001b[0m status_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(matches[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus_code\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    110\u001b[0m class_: Union[Type[InformationalResponse], Type[Response]] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    111\u001b[0m     InformationalResponse \u001b[38;5;28;01mif\u001b[39;00m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m200\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m Response\n\u001b[1;32m    112\u001b[0m )\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclass_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_decode_header_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_parsed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreason\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreason\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/h11/_events.py:147\u001b[0m, in \u001b[0;36m_ResponseBase.__init__\u001b[0;34m(self, headers, status_code, http_version, reason, _parsed)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m     _parsed: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    145\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHeaders\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m, headers)\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.17_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/abc.py:119\u001b[0m, in \u001b[0;36mABCMeta.__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__instancecheck__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, instance):\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_abc_instancecheck\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "llm_flow(ollama_models[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8029f1",
   "metadata": {},
   "source": [
    "llm_flow(ollama_models[0])\n",
    "\n",
    "Accuracy per Emotion:\n",
    "Neutral: 1912/2254 = 0.85\n",
    "Joy: 5749/11045 = 0.52\n",
    "Sadness: 3712/6722 = 0.55\n",
    "Fear: 1709/5410 = 0.32\n",
    "Surprise: 470/4062 = 0.12\n",
    "Anger: 2722/4297 = 0.63\n",
    "Shame: 110/146 = 0.75\n",
    "Disgust: 201/856 = 0.23\n",
    "mistral finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d1d217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea9921d4",
   "metadata": {},
   "source": [
    "\n",
    "llm_flow(ollama_models[1])\n",
    "\n",
    "\n",
    "Accuracy per Emotion:\n",
    "Neutral: 276/2254 = 0.12\n",
    "Joy: 2316/11045 = 0.21\n",
    "Sadness: 1411/6722 = 0.21\n",
    "Fear: 1139/5410 = 0.21\n",
    "Surprise: 81/4062 = 0.02\n",
    "Anger: 50/4297 = 0.01\n",
    "Shame: 14/146 = 0.10\n",
    "Disgust: 241/856 = 0.28\n",
    "tinyllama finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfd7356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Define emotion labels\n",
    "emotion_labels = ['neutral', 'joy', 'sadness', 'fear', 'surprise', 'anger', 'shame','disgust']\n",
    "\n",
    "def hf_flow(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "    # Load SentenceTransformer model\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    # Precompute label embeddings\n",
    "    label_embeddings = model.encode(emotion_labels, convert_to_tensor=True)\n",
    "\n",
    "    # Define emotion classifier\n",
    "    def classify_emotion(text):\n",
    "        if not isinstance(text, str):\n",
    "            return \"unknown\"\n",
    "        embedding = model.encode(text, convert_to_tensor=True)\n",
    "        scores = util.pytorch_cos_sim(embedding, label_embeddings)[0]\n",
    "        best_idx = scores.argmax().item()\n",
    "        return emotion_labels[best_idx].lower()\n",
    "\n",
    "    # Load dataset\n",
    "    df = pd.read_csv(\"../data/emotion_dataset_raw.csv\")\n",
    "    # df_sample = df[['Text']].dropna().copy().head(100)\n",
    "    df_sample = df[['Text']].dropna().copy()\n",
    "    \n",
    "    df_sample['LLM_Prediction'] = df_sample['Text'].apply(classify_emotion)\n",
    "\n",
    "    # Save predictions\n",
    "    output_file = model_name.replace(\"/\", \"_\") + \"_predictions_sample.csv\"\n",
    "    df_sample.to_csv(output_file, index=False)\n",
    "\n",
    "    # Prepare ground truth\n",
    "    df_truth = df[['Text', 'Emotion']].dropna().reset_index(drop=True)\n",
    "    df_pred = df_sample[['Text', 'LLM_Prediction']].reset_index(drop=True)\n",
    "\n",
    "    # Merge and normalize labels\n",
    "    df_compare = df_truth.copy()\n",
    "    df_compare['LLM_Prediction'] = df_pred['LLM_Prediction'].str.strip().str.lower()\n",
    "    df_compare['Emotion'] = df_compare['Emotion'].str.strip().str.lower()\n",
    "\n",
    "    # Filter only valid labels\n",
    "    df_compare = df_compare[df_compare['LLM_Prediction'].isin(emotion_labels)]\n",
    "\n",
    "    # Accuracy\n",
    "    overall_accuracy = accuracy_score(df_compare['Emotion'], df_compare['LLM_Prediction'])\n",
    "    print(f\"\\n🔍 Overall Accuracy: {overall_accuracy:.2f}\")\n",
    "\n",
    "    print(\"\\n📊 Accuracy per Emotion:\")\n",
    "    for emotion in emotion_labels:\n",
    "        subset = df_compare[df_compare['Emotion'] == emotion]\n",
    "        if len(subset) > 0:\n",
    "            correct = (subset['Emotion'] == subset['LLM_Prediction']).sum()\n",
    "            print(f\"{emotion.title()}: {correct}/{len(subset)} = {correct/len(subset):.2f}\")\n",
    "        else:\n",
    "            print(f\"{emotion.title()}: 0/0 = N/A\")\n",
    "\n",
    "    print(f\"\\n✅ {model_name} finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec581803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4e0e8598564d6b80dc9133d8995748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading .gitattributes:   0%|          | 0.00/1.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac49be22c1b4fbda6429071a297c8c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb77a20dd97468ab3ef1d887b721ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7efd924efd9420590e516b86f952686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4a9f999923486687587cfac933c9ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270a47cfe6854156b9f2a63c8d925408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5aafaedff54b21aeb3deadbbcd8e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd7eb8fc9614d7e94f5209b511ba4db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.onnx:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7332838f628b421093d554d06b8dea86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model_O1.onnx:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b346a370f5474338a9e8e248d8ca94e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model_O2.onnx:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c190b820fe499fb544e5617ad15c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model_O3.onnx:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec7a860ecec4b458ab6a6a451df2dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model_O4.onnx:   0%|          | 0.00/66.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b28715cab34ba79aa8fa9e7c78c4a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model_qint8_arm64.onnx:   0%|          | 0.00/34.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "316412f87108422c8c6d5c0d6c804527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model_qint8_arm64.onnx:   0%|          | 0.00/34.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2eb712e09c4ff9822b2208613a1b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model_qint8_arm64.onnx:   0%|          | 0.00/34.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72bc06f64064cfe8b431d8d1056bc45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model_quint8_avx2.onnx:   0%|          | 0.00/34.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8979b51b27324b1a8b834c5f1e15e1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading openvino_model.bin:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e30dbbee2364ecf92bd535934adccfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading openvino_model.xml:   0%|          | 0.00/398k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757ea7b793e94dafa11f7bbf0fb9a6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_qint8_quantized.bin:   0%|          | 0.00/33.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1128041adf40208a7fa9aa87912990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_qint8_quantized.xml:   0%|          | 0.00/708k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "005ac0c0c9464ea2b159a5d63459c786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f308bc912f4c97a25de6a4e9552e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6964baa63d394849a5fed8f1ddaf7fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b905b90804c471bb245bb0a678a498e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51969535bb6640aa90d89bea19ea6fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/352 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf45d16ab94f4651a1cabffa7851506b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae26567d6c8d4bddb1c2d1fd809b1a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72f3acde76c42ab8dc103ebb7789641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Overall Accuracy: 0.41\n",
      "\n",
      "📊 Accuracy per Emotion:\n",
      "Neutral: 92/2254 = 0.04\n",
      "Joy: 4858/11045 = 0.44\n",
      "Sadness: 3676/6722 = 0.55\n",
      "Fear: 2715/5410 = 0.50\n",
      "Surprise: 863/4062 = 0.21\n",
      "Anger: 1691/4297 = 0.39\n",
      "Shame: 47/146 = 0.32\n",
      "Disgust: 301/856 = 0.35\n",
      "\n",
      "✅ sentence-transformers/all-MiniLM-L12-v2 finished.\n"
     ]
    }
   ],
   "source": [
    "hf_flow(\"sentence-transformers/all-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aae6e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f756508496aa4be280e11a355cdb4bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading .gitattributes:   0%|          | 0.00/1.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40015093ae54a37a708e469a2e54538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387b9b435ed1409980ffbb5ed09f8e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading README.md:   0%|          | 0.00/10.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aca4f39cb6f40a7aa91685dc2af64bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d7e46bfc63478ab862f936de58c7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e6a300f76847e1bf0cab24a2cac018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b6c6bd1874496cbe976c8979798fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f30439e41c7477e9874c92236c0b69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.onnx:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919b077314f045cea286421cdf7020a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model_O1.onnx:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab69e27f63c347c68f381a73d23c29f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model_O2.onnx:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd95028b3db46e881a0e81fccf3874f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model_O3.onnx:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393b461b131b43d78d060018dd87e0c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model_O4.onnx:   0%|          | 0.00/218M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e16762e0c3e44efb61a5868b55af5aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model_qint8_arm64.onnx:   0%|          | 0.00/110M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "743c747977d54b13b0728febccea7cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model_qint8_arm64.onnx:   0%|          | 0.00/110M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f655cfc56e3742b48dd9e988152b651f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model_qint8_arm64.onnx:   0%|          | 0.00/110M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30463c329cdd4b44b69151c9b78f531f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model_quint8_avx2.onnx:   0%|          | 0.00/110M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c87148c064a42ec9ad6c550680fa5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading openvino_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902dd6fc13cf431d9fead0dafe887a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading openvino_model.xml:   0%|          | 0.00/433k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ecc2b1f34ee4915a3c78dc79cd40919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_qint8_quantized.bin:   0%|          | 0.00/110M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5fc7c35e7ce43f0880fc76f710273e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_qint8_quantized.xml:   0%|          | 0.00/742k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02524c0791b44943b00b47192663dcb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9804b879a9412494b17ca938ea20e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2090b4427bb43debc91d8ea6d41411d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39bc46c035394f248bf7b0f58ff73bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5600d5f68564476f89a09d07229a5d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23d327cf6cb4f92a3dae4f2c0a1a9ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading train_script.py:   0%|          | 0.00/13.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126f340d2bb54f7e8e677feb9a8b63ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a2b7091d804b5d9d283f4bc20d9e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Overall Accuracy: 0.44\n",
      "\n",
      "📊 Accuracy per Emotion:\n",
      "Neutral: 186/2254 = 0.08\n",
      "Joy: 4960/11045 = 0.45\n",
      "Sadness: 3345/6722 = 0.50\n",
      "Fear: 2343/5410 = 0.43\n",
      "Surprise: 1864/4062 = 0.46\n",
      "Anger: 2160/4297 = 0.50\n",
      "Shame: 33/146 = 0.23\n",
      "Disgust: 323/856 = 0.38\n",
      "\n",
      "✅ sentence-transformers/all-mpnet-base-v2 finished.\n"
     ]
    }
   ],
   "source": [
    "hf_flow(\"sentence-transformers/all-mpnet-base-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c0ea7915",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_truth = pd.read_csv(\"../data/emotion_dataset_raw.csv\")\n",
    "df_truth = df_truth[['Text', 'Emotion']].dropna().reset_index(drop=True)\n",
    "\n",
    "def eval(model_name):\n",
    "    # Load LLM predictions\n",
    "    df_pred = pd.read_csv(model_name+\"_predictions_sample.csv\")\n",
    "    df_pred = df_pred[['Text', 'LLM_Prediction']].dropna().reset_index(drop=True)\n",
    "\n",
    "    # Merge and normalize\n",
    "    df_compare = df_truth.copy()\n",
    "    df_compare['LLM_Prediction'] = df_pred['LLM_Prediction'].str.strip().str.lower()\n",
    "    df_compare['Emotion'] = df_compare['Emotion'].str.strip().str.lower()\n",
    "\n",
    "    # Overall accuracy\n",
    "    overall_accuracy = accuracy_score(df_compare['Emotion'], df_compare['LLM_Prediction'])\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.2f}\")\n",
    "\n",
    "    # Accuracy per emotion\n",
    "    print(\"\\nAccuracy per Emotion:\")\n",
    "    for emotion in df_compare['Emotion'].unique():\n",
    "        subset = df_compare[df_compare['Emotion'] == emotion]\n",
    "        correct = (subset['Emotion'] == subset['LLM_Prediction']).sum()\n",
    "        total = len(subset)\n",
    "        print(f\"{emotion.title()}: {correct}/{total} = {correct/total:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b60efe01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.48\n",
      "\n",
      "Accuracy per Emotion:\n",
      "Neutral: 1912/2254 = 0.85\n",
      "Joy: 5749/11045 = 0.52\n",
      "Sadness: 3712/6722 = 0.55\n",
      "Fear: 1709/5410 = 0.32\n",
      "Surprise: 470/4062 = 0.12\n",
      "Anger: 2722/4297 = 0.63\n",
      "Shame: 110/146 = 0.75\n",
      "Disgust: 201/856 = 0.23\n"
     ]
    }
   ],
   "source": [
    "# ollama_models = [\n",
    "#     \"mistral\",\n",
    "#     \"llama2\",\n",
    "#     \"tinyllama\",\n",
    "#     # \"phi\",\n",
    "#     # \"gemma\"\n",
    "# ]\n",
    "eval(\"mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "afabd06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.16\n",
      "\n",
      "Accuracy per Emotion:\n",
      "Neutral: 295/2254 = 0.13\n",
      "Joy: 2238/11045 = 0.20\n",
      "Sadness: 1478/6722 = 0.22\n",
      "Fear: 1145/5410 = 0.21\n",
      "Surprise: 62/4062 = 0.02\n",
      "Anger: 42/4297 = 0.01\n",
      "Shame: 13/146 = 0.09\n",
      "Disgust: 236/856 = 0.28\n"
     ]
    }
   ],
   "source": [
    "eval(\"tinyllama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1bd9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating sentence_transformers_all_MiniLM_L6_v2...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sentence_transformers_all_MiniLM_L6_v2_predictions_sample.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m model_names:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[49], line 6\u001b[0m, in \u001b[0;36meval\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21meval\u001b[39m(model_name):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Load LLM predictions\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     df_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_predictions_sample.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     df_pred \u001b[38;5;241m=\u001b[39m df_pred[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLLM_Prediction\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Merge and normalize\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Desktop/ECE284/project/Emotion-Detection-in-Text/tf-env/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sentence_transformers_all_MiniLM_L6_v2_predictions_sample.csv'"
     ]
    }
   ],
   "source": [
    "model_names = [\n",
    "    \"sentence-transformers_all-MiniLM-L6-v2_predictions_sample.csv\",\n",
    "    \"sentence-transformers_all-MiniLM-L12-v2_predictions_sample.csv\",\n",
    "    \"sentence-transformers_all-mpnet-base-v2_predictions_sample.csv\",\n",
    "    \"sentence-transformers_gtr-t5-large_predictions_sample.csv\",\n",
    "    \"sentence-transformers_gtr-t5-xl_predictions_sample.csv\"\n",
    "]\n",
    "\n",
    "# Loop through and call each function by name using eval()\n",
    "for model in model_names:\n",
    "    print(f\"Evaluating {model}...\")\n",
    "    eval(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739f6ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
